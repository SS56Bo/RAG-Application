{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddd75b8a",
   "metadata": {},
   "source": [
    "# Importing Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "daa25c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45eaa159",
   "metadata": {},
   "source": [
    "# Formatting text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1741ce0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_format(text: str)->str :\n",
    "    cleaner_text = text.replace(\"\\n\", \" \").strip()\n",
    "\n",
    "    return cleaner_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c48ceb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_from_source(path: str)->list[dict]:\n",
    "    doc = fitz.open(path)\n",
    "    pages_text = []\n",
    "\n",
    "    for pageno, pagecontent in tqdm(enumerate(doc)):\n",
    "        text = pagecontent.get_text()\n",
    "        text = text_format(text=text)\n",
    "        pages_text.append({\"Page No.\": pageno, \"page_char_count\": len(text), \"page_word_count\": len(text.split(\" \")), \"page_sentence_count\": len(text.split(\".\")), \"page_token_count\": len(text)/4, \"text\": text})\n",
    "        \n",
    "    return pages_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea1ecf6",
   "metadata": {},
   "source": [
    "# Using our custom function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "78bcf739",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48it [00:00, 752.64it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'Page No.': 17,\n",
       "  'page_char_count': 1584,\n",
       "  'page_word_count': 257,\n",
       "  'page_sentence_count': 28,\n",
       "  'page_token_count': 396.0,\n",
       "  'text': '5 Framework Overview and Comparison This section presents an overview of major GPU programming frameworks used in high- performance computing: CUDA, HIP with CUDA Backend, HIP on ROCm, and OpenCL. A comparison based on hardware compatibility, ease of use, and programming features is also provided. 5.1 CUDA (Compute Unified Device Architecture) CUDA is a parallel computing platform and programming model developed by NVIDIA. It allows developers to use C/C++ syntax to write programs that run directly on NVIDIA GPUs. 1. CUDA provides low-level control over thread hierarchy, memory management, and synchronization. 2. It enables fine-tuned performance on NVIDIA hardware. 5.2 HIP with CUDA Backend on NVIDIA GPUs HIP (Heterogeneous-Compute Interface for Portability) is a C++ runtime API developed by AMD that allows developers to write portable code targeting both AMD and NVIDIA GPUs. 1. On NVIDIA GPUs, HIP code is compiled using the CUDA backend. 2. The syntax of HIP is nearly identical to CUDA, allowing for easy translation via tools like hipify. 3. HIP with CUDA backend has been used to run programs on NVIDIA GPUs during this project. 5.3 HIP on ROCm (AMD GPUs) On AMD GPUs, HIP runs in the ROCm (Radeon Open Compute) environment. 1. ROCm is AMD’s open-source software platform for GPU computing. 2. It supports HIP as a primary programming model. 3. The same HIP code written for NVIDIA can often be compiled and executed on AMD hardware with minimal changes. 4. HIP on ROCm was used to evaluate programs such as matrix multiplication and vector addition on AMD GPUs. 18'},\n",
       " {'Page No.': 10,\n",
       "  'page_char_count': 1698,\n",
       "  'page_word_count': 239,\n",
       "  'page_sentence_count': 13,\n",
       "  'page_token_count': 424.5,\n",
       "  'text': 'Feature CPU GPU Core Count Few powerful cores Thousands of simpler cores Control Unit Advanced Lightweight ALUs Limited per core Massive number per chip Cache Size Large (L1, L2, L3) Smaller Thread Concurrency Dozens Tens of thousands Latency vs Throughput Low latency High throughput Designed For Logic-heavy tasks Data-parallel tasks Table 1: CPU vs GPU Comparison 2.5 Architectural Differences • CPUs focus on low-latency, complex control logic with deep cache hierarchies. • GPUs offer high-throughput, multiple ALUs, and thousands of threads. • GPUs use special memory structures like shared memory, registers, etc. 2.6 Workload Handling and Use-Case Differences Criteria CPU Workload GPU Workload Best For Complex logic, system tasks Repetitive numerical tasks Example Applications OS scheduling, decision trees Neural network training Thread Flexibility Dynamic, supports branching Fixed-pattern, less flexible Memory Access Coherent Needs careful optimization Table 2: CPU vs GPU Use-case Comparison Therefore, to summarize, CPUs are ideal for tasks that require complex decision- making and less concurrency. GPUs excel at massive data-parallel tasks. In modern systems, both are used together in a heterogeneous computing environment for maximum efficiency. 2.7 Heterogeneous Computing Heterogeneous computing refers to using different types of processors—like CPUs and GPUs—together in a single system to maximize performance. This approach allows the CPU to handle logic-heavy tasks while the GPU handles compute-heavy, data-parallel tasks. Frameworks like HIP and OpenCL are designed to support heterogeneous systems, allowing code to run on multiple platforms with minimal changes. 11'},\n",
       " {'Page No.': 9,\n",
       "  'page_char_count': 1916,\n",
       "  'page_word_count': 282,\n",
       "  'page_sentence_count': 20,\n",
       "  'page_token_count': 479.0,\n",
       "  'text': '2 Overview of Key Concepts 2.1 What is Parallel Programming? Parallel programming is a way of solving problems by dividing a task into smaller sub- tasks and executing them simultaneously across multiple processors or cores. This significantly reduces execution time and is especially useful for large, compute-intensive problems. Instead of doing one thing at a time (sequential execution), parallel programming lets us do many things at once, taking advantage of modern multi-core processors and GPUs. 2.2 Types of Parallelism There are two main types of parallelism: • Data Parallelism: The same operation is performed on different pieces of data at the same time. Example: Adding two large arrays element-wise. • Task Parallelism: Different tasks (functions or operations) are performed in par- allel, possibly on the same or different data. Example: While one thread reads data from a file, another processes a different part of it. 2.3 Applications of Parallel Programming Parallel programming is used in various real-world domains: • Artificial Intelligence and Machine Learning • Scientific Simulations (e.g., weather forecasting) • Computer Graphics and Gaming • Image and Signal Processing • Cryptography and Blockchain • Financial Modeling 2.4 CPU vs GPU CPUs are designed for general-purpose tasks. They have a few powerful cores optimized for sequential execution and complex decision-making logic. This makes them suitable for running operating systems and everyday applications. GPUs, on the other hand, are made for high-speed parallel processing. They contain thousands of smaller, simpler cores that can execute many threads simultaneously. This architecture is ideal for graphics rendering, scientific computing, and machine learning tasks that involve repetitive numerical operations on large datasets. While both CPUs and GPUs are processing units, their design goals and capabilities differ: 10'}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "text_info = get_text_from_source(path=\"test.pdf\")\n",
    "random.sample(text_info, k=3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
